<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Copy Text Buttons</title>
    <style>
        button {
            margin: 5px;
        }

        body {
            background-color: #f0f0f0;
            /* Light gray background */
            font-family: Arial, sans-serif;
            text-align: center;
        }

        button {
            margin: 10px;
            padding: 10px;
            font-size: 16px;
            background-color: #ddd;
            /* Light gray button background */
            border: 1px solid #aaa;
            /* Dark gray border */
            cursor: pointer;
        }

        button:hover {
            background-color: #ccc;
            /* Slightly darker background on hover */
        }
    </style>
</head>

<body>

    <button onclick="copyText(text1)">1a using Naive Bayes algorithm</button>
    <button onclick=" copyText(text2)">1b using the SVM classifier</button>
    <button onclick="copyText(text3)">2a clustering technique KMeans </button>
    <button onclick="copyText(text4)">2b  using hierarchical clustering</button>
    <button onclick="copyText(text5)">3 Perform linear regression</button>
    <button onclick="copyText(text6)">4 Perform logistic regression</button>
    <button onclick="copyText(text7)">5 Perform data analysis</button>
    
    
    <p id="copiedMsg"></p>
    <script>
        var text1 = `#Pract 1 :using Naive Bayes algorithm

import numpy as np
import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
df=pd.read_csv('/content/spam (1).csv', encoding='latin-1')
df=df[['Message','Category']]
df.columns=['SMS','Type']
countvec =
CountVectorizer(ngram_range=(1,4),stop_words='english',strip_accents='unic
ode',max_features=1000)
bow = countvec.fit_transform(df.SMS)
X_train = bow.toarray()
Y_train = df.Type.values
mnb = MultinomialNB()
mnb.fit(X_train, Y_train)
text1 = countvec.transform(['free gifts for all'])
print('free gifts for all')
print(mnb.predict(text1))
text2 = countvec.transform(['we will go for lunch'])
print('we will go for lunch')
print(mnb.predict(text2))

    `;
        var text2 = `#Practical 1b - 1busing the SVM classifier

        #Practical 1b - 1busing the SVM classifier

        from sklearn import svm, datasets
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
iris = datasets.load_iris()
X = iris.data[:, :2] # we only take the first two features
y = iris.target
x_train, x_test, y_train, y_test = train_test_split(X, y, random_state =
0, test_size = 0.3)
clf = svm.SVC(kernel='linear', C=1).fit(x_train, y_train)
#clf = svm.SVC(kernel='rbf', C=1,gamma=0).fit(x_train, y_train)
classifier_predictions = clf.predict(x_test)
print(accuracy_score(y_test, classifier_predictions)*100)
h = 0.02
x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
xx, yy = np.meshgrid(np.arange(x_min, x_max, h),np.arange(y_min, y_max,
h))
Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])
Z = Z.reshape(xx.shape)
plt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.3)
plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.coolwarm)
plt.xlabel('Sepal length')
plt.ylabel('Sepal width')
plt.xlim(xx.min(), xx.max())
plt.ylim(yy.min(), yy.max())
#plt.xticks(())
#plt.yticks(())
plt.title("Linear")
plt.show()

`;

        var text3 = `
        #Pract 2 - 2 clustering technique(KMeans 

        import numpy as nm
import matplotlib.pyplot as mtp
import pandas as pd
dataset = pd.read_csv('/content/Mall_Customers - Mall_Customers (1).csv')
x = dataset.iloc[:, [3, 4]].values
from sklearn.cluster import KMeans
wcss_list= [] #Initializing the list for the values of WCSS
#Using for loop for iterations from 1 to 10.
for i in range(1, 11):
kmeans = KMeans(n_clusters=i, init='k-means++', random_state= 42)
kmeans.fit(x)
wcss_list.append(kmeans.inertia_)
mtp.plot(range(1, 11), wcss_list)
mtp.title('The Elobw Method Graph')
mtp.xlabel('Number of clusters(k)')
mtp.ylabel('wcss_list')
mtp.show()
kmeans = KMeans(n_clusters=5, init='k-means++', random_state= 42)
y_predict= kmeans.fit_predict(x)
print(y_predict)
mtp.scatter(x[y_predict == 0, 0], x[y_predict == 0, 1], s = 100, c =
'blue', label = 'Cluster 1') #for first cluster
mtp.scatter(x[y_predict == 1, 0], x[y_predict == 1, 1], s = 100, c =
'green', label = 'Cluster 2') #for second cluster
mtp.scatter(x[y_predict== 2, 0], x[y_predict == 2, 1], s = 100, c = 'red',
label = 'Cluster 3') #for third cluster
mtp.scatter(x[y_predict == 3, 0], x[y_predict == 3, 1], s = 100, c =
'cyan', label = 'Cluster 4') #for fourth cluster
mtp.scatter(x[y_predict == 4, 0], x[y_predict == 4, 1], s = 100, c =
'magenta', label = 'Cluster 5') #for fifth cluster
mtp.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1],
s = 300, c = 'yellow', label = 'Centroid')
mtp.title('Clusters of customers')
mtp.xlabel('Annual Income (k$)')
mtp.ylabel('Spending Score (1-100)')
mtp.legend()
mtp.show()
`;

        var text4 = ` # 2b using hierarchical clustering

        import pandas as pd
import numpy as nm
import matplotlib.pyplot as plt
%matplotlib Inline
data = pd.read_csv('/content/Wholesale customers data - Wholesale
customers data (1).csv')
data.head()
from sklearn.preprocessing import normalize
data_scaled = normalize(data)
data_scaled = pd.DataFrame(data_scaled, columns=data.columns)
data_scaled.head()
import scipy.cluster.hierarchy as shc
plt.figure(figsize=(10,7))
plt.title("Dendograms")
dend = shc.dendrogram(shc.linkage(data_scaled, method='ward'))
plt.axhline(y=6, color='r', linestyle='--')
from sklearn.cluster import AgglomerativeClustering
cluster = AgglomerativeClustering(n_clusters=2, metric='euclidean',
linkage='ward')
cluster.fit_predict(data_scaled)
plt.figure(figsize=(10, 7))
plt.scatter(data_scaled['Milk'], data_scaled['Grocery'],
c=cluster.labels_)
`;

        var text5 = `#3 Perform linear regression

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
dataset = pd.read_csv('/content/salary_data - salary_data.csv')
X = dataset.iloc[: , :-1].values
y = dataset.iloc[: , -1].values
print (dataset.head())
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3,
random_state = 0)
from sklearn.linear_model import LinearRegression
regressor = LinearRegression()
regressor.fit(X_train, y_train)
y_pred = regressor.predict(X_test)
pd.DataFrame(data={'Actuals': y_test, 'Predictions': y_pred})
plt.scatter(X_train, y_train, color = 'red')
plt.plot(X_train, regressor.predict(X_train), color = 'green')
plt.title('Salary vs Experience (Training set)')
plt.xlabel('Years of Experience')
plt.ylabel('Salary')
plt.show()
plt.scatter(X_test, y_test, color = 'red')
plt.plot(X_train, regressor.predict(X_train), color = 'green')
plt.title('Salary vs Experience (Test set)')
plt.xlabel('Years of Experience')
plt.ylabel('Salary')
plt.show()
        
  `;
  
        var text6 = ` #4 : Perform logistic regression
        import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt # Visualizing
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
student_data = pd.read_csv("/content/Admission_P1A - Admission_P1A
(1).csv")
col_names = student_data.columns
#Print first ten records
student_data.head(10)
feature_cols = ['gre', 'gpa', 'rank']
X = student_data[feature_cols]
Y=student_data.admit
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3,
random_state=1)
clf = LogisticRegression()
clf.fit(X_train,Y_train)
Y_pred = clf.predict(X_test)
print("Accuracy:",round(accuracy_score(Y_test, Y_pred),1))
# Prediction
new={'gre':[260],'gpa':[2.67],'rank':[1] }
sc2 = pd.DataFrame(new,columns= ['gre','gpa','rank'])
Y_pred=clf.predict(sc2)
print (sc2)
print ("Forecast is:",Y_pred
`;

        var text7 = `#5 Perform data analysis

        from pandas import read_csv
from matplotlib import pyplot
from statsmodels.tsa.ar_model import AutoReg
from sklearn.metrics import mean_squared_error
from math import sqrt
# load dataset
series = read_csv('/content/daily-min-temperatures.csv', header=0,
index_col=0,parse_dates=True)
print(series.head(10))
print("===================================================================
=====")
# split dataset
X = series.values
print(X)
print("===================================================================
=====")
train, test = X[1:len(X)-7], X[len(X)-7:]
# train autoregression
model = AutoReg(train,10)
model_fit = model.fit()
print('Lag: %s' % model_fit.ar_lags)
print('Coefficients: %s' % model_fit.params)
# make predictions
predictions = model_fit.predict(start=len(train),
end=len(train)+len(test)-1, dynamic=False)
for i in range(len(predictions)):
print('predicted=%f, expected=%f' % (predictions[i], test[i]))
rmse = sqrt(mean_squared_error(test, predictions))
print('Test RMSE: %.3f' % rmse)
# plot results
pyplot.plot(test)
pyplot.plot(predictions, color='red')
pyplot.show()

`;


function copyText(text) {
    navigator.clipboard.writeText(text).then(function () {
        document.getElementById('copiedMsg').innerHTML = "Text Copied"
    }).catch(function (err) {
        console.error('Unable to copy text', err);
    });
}
</script>

</body>

</html>
